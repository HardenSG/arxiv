# 深度研究Agent的随机性评估：以信息获取MDP框架系统性分析

**论文标题**：Evaluating Stochasticity in Deep Research Agents

**作者**：Haotian Zhai, Elias Stengel-Eskin, Pratik Patil, Leqi Liu（德克萨斯大学奥斯汀分校）

**arXiv ID**：2602.23271

**研究领域**：人工智能（cs.AI）、大语言模型Agent系统

---

## 1. 论文基本信息

### 核心问题

深度研究代理（Deep Research Agents, DRAs）是一类专门用于自主知识发现的LLM驱动Agent系统，广泛应用于金融决策、医疗分析、科学发现等领域。然而，现有研究往往关注最终输出质量（如答案准确性），而忽视了一个关键部署障碍：**随机性**。在相同查询条件下，DRAs的多次执行可能产生截然不同的研究结论、发现和引用来源。这种随机性严重影响了DRA系统的可靠性和实际部署价值。

### 问题的重要性

随机性问题的实际影响跨越从普通用户体验到高风险专业应用的广泛场景。对于普通用户，DRAs常被用于日常决策（如医疗信息检索），缺乏领域专业知识来验证系统输出的用户往往将DRA输出视为"标准答案"。试想，如果一个关于药物安全性的DRA在三次运行中给出相互矛盾的建议，这种随机性本身就传递了不可靠的信号，可能导致用户采纳错误建议。

对于专业用户，挑战则是操作层面的。在制药研发或量化金融等领域，DRAs被用于自动化高吞吐量工作流程。虽然这些专家能够区分严谨和非严谨的输出，但如果同一金融工具每次查询都产生不同的风险画像，专家就必须手动验证每次执行。在这种情况下，随机性将本应提高效率的工具变成了负担——自动化节省的时间被严谨验证的必要所抵消。

---

## 2. 研究背景与动机

### 现有工作的不足

当前DRA研究主要聚焦于提升输出质量（如有标准答案时的准确率），但系统性地忽视了可靠性这一根本障碍。传统的评估基准（如WebWalkerQA）主要关注直接检索准确率，无法捕捉综合研究报告生成的复杂性。

### 研究空白

该论文首次系统性地提出了DRA随机性问题的形式化定义和评估框架。具体而言：

1. **随机性来源不明**：之前没有工作明确识别并量化DRA系统中随机性的具体来源
2. **传播机制不清**：早期决策步骤的随机性如何级联影响最终输出的机制未被研究
3. **缓解策略缺乏**：如何有效降低随机性同时保持输出质量的方法论尚未探索

### 与现有LLM工作的关系

该研究建立在以下基础之上：
- **ReAct框架**：采用ReAct作为代表性DRA实现，将Agent操作形式化为查询生成（信息获取）、摘要（信息压缩）和推理（推理）的迭代循环
- **RAG系统**：继承自检索增强生成范式，但扩展到长文本研究任务
- **FactScore评估**：采用原子发现分解方法进行输出评估

---

## 3. 核心贡献

该论文的贡献可明确分为以下几类：

### 理论贡献

1. **信息获取MDP形式化**：将深度研究Agent的执行建模为信息获取马尔可夫决策过程（MDP），为随机性的原则性分析提供了统一抽象
2. **随机性分解框架**：数学上形式化了DRA随机性分解为传播随机性和内在随机性，后者进一步分解为信息获取、信息压缩和推理三个模块的贡献
3. **总方差度量**：提出使用协方差矩阵的迹（Total Variance, TV）作为随机性的统一量化指标

### 方法论贡献

1. **多层次随机性指标**：设计了答案级、发现级和引用级三个层次的随机性评估指标
2. **温度消融实验**：通过温度控制不同策略模块的随机性，进行可解释的消融实验
3. **两种缓解策略**：提出了基于结构化输出的约束方法和基于查询交集的集成方法

### 实验贡献

1. **系统性的随机性分析**：在WebWalkerQA数据集上进行了全面的模块级和时间级消融实验
2. **随机性与准确性关系**：首次揭示高随机性并不必然带来高准确性
3. **缓解效果验证**：在DeepSearchQA数据集上验证了缓解策略的有效性，平均降低22%随机性

---

## 4. 方法论深度解析

### 4.1 信息获取MDP建模

论文将单次DRA运行建模为信息获取MDP，这是本文的理论核心。形式化定义如下：

**状态空间**：对于查询 $q \in \mathcal{Q}$，令 $\mathcal{F}(q) = \{f_1, ..., f_N\}$ 表示与查询相关的原子发现 universe。状态 $\mathbf{b}_t \in \{0,1\}^N$ 表示截至步骤t已获取的证据支持的发现，其中 $\mathbf{b}_t[k]=1$ 表示发现 $f_k$ 被当前证据支持。

**动作空间**：$\mathcal{A} = \mathcal{S} \cup \{\text{STOP}\}$，其中 $\mathcal{S}$ 是允许的搜索查询集合。

**三个核心策略模块**：

1. **信息获取策略** $\pi_{\text{query}}$：$a_t \sim \pi_{\text{query}}(\cdot | q, \mathbf{b}_t)$ — 决定生成什么搜索查询或是否停止
2. **信息压缩策略** $\pi_{\text{sum}}$：$h_t \sim \pi_{\text{sum}}(\cdot | q, \mathbf{b}_t, i_t)$ — 将检索内容压缩为中间表示（笔记、提取的断言、结构化表格）
3. **推理策略** $\pi_{\text{update}}$：$\mathbf{b}_{t+1} \sim \pi_{\text{update}}(\cdot | q, \mathbf{b}_t, h_t, a_t)$ — 整合新信息更新知识状态

### 4.2 随机性度量

论文提出使用**总方差（Total Variance, TV）**作为随机性的标量度量：

$$\text{TV}(\mathbf{X}) \triangleq \text{Tr}(\Sigma) = \frac{1}{2}\mathbb{E}\left[||\mathbf{X}_1 - \mathbf{X}_2||^2\right]$$

其中 $\mathbf{X}_1$ 和 $\mathbf{X}_2$ 是独立同分布的随机向量副本。为使指标可比较，对每个实现进行 $\ell_2$ 归一化：

$$\widetilde{\mathbf{x}}_i = \mathbf{x}_i / ||\mathbf{x}_i||_2$$

TV指标的统一性在于：对于one-hot编码的答案，TV等于两次运行给出不同规范答案的经验概率；对于二值发现/引用，TV类似于余弦重叠度——当运行共享的规范项相对于其大小越少时，指标越高。

### 4.3 随机性分解

论文将任意步骤 $t$ 的随机性概念性分解为两个主要组件：

**传播随机性**：从之前步骤继承的随机性。由于DRA当前动作依赖于其先前状态，任何早期引入的随机性自然级联。

**内在随机性**：由Agent内部策略在当前时间步引入的新随机性。即使前一个状态绝对确定，LLM驱动的组件仍会表现出变异性。

内在随机性进一步按三个功能模块分类：
- $\Delta_{\text{Query}}$：查询生成时的随机性
- $\Delta_{\text{Sum}}$：摘要提取时的随机性  
- $\Delta_{\text{Update}}$：推理/信念更新时的随机性

### 4.4 缓解策略

**方法1：结构化输出约束**

对信息压缩 $\pi_{\text{sum}}$ 和推理 $\pi_{\text{update}}$ 施加JSON或Markdown预定义模式约束，期望减少输出风格变化，从而降低 $\Delta_{\text{Sum}}$ 和 $\Delta_{\text{Update}}$。

**方法2：早期查询随机性减少**

采用基于共识的集成方法。发出 $N$ 组独立查询，只保留交集：
$$a_t = \bigcap_{i=1}^{N} \text{queries}_i$$

为保持效率，随时间衰减 $N \rightarrow 1$。

---

## 5. 实验分析与实证评估

### 数据集

1. **WebWalkerQA**（用于消融实验）：20个实例，QA任务
2. **DeepSearchQA**（用于缓解验证）：20个实例，更复杂的研究任务

### 基线与设置

- **骨干LLM**：Qwen3-30B-A3B-Instruct-2507（消融实验），Qwen3-235B-A22B-Instruct-2507-tput（缓解实验）
- **搜索API**：You.com（设计为对相同查询返回一致结果）
- **运行次数**：$k=10$ 次独立运行
- **温度设置**：$\lambda = 0.5$ 和 $\lambda = 1.0$（消融），$\lambda = 1.0$（缓解实验）

### 关键实验结果

#### Finding 1：早期随机性对最终随机性影响最大

在相同模块条件下，在较早步骤注入较高随机性比在较晚步骤产生更大的最终方差。这直接证实了传播随机性对最终输出的显著影响——早期状态的不确定性被"携带向前"到最终方差。

#### Finding 2：发现、引用和答案随机性正相关

所有方差指标之间观察到强正相关（见论文图2b），证实这些指标捕捉了知识状态随机性的共同潜在概念。

#### Finding 3：方差随温度单调增加

较高的采样温度一致导致较大的估计总方差。这种单调增加表明温度可以作为总方差的直接缩放因子。

#### Finding 4：高随机性不意味着高准确性

这是最具启发性的发现之一。更大的TV不必然带来更高的答案准确率。表2显示，许多情况下随机性增加但准确率持平或下降。

#### Finding 5：发现比引用更具随机性

发现的平均TV为0.76，而引用为0.44。这表明尽管DRAs检索相对一致的证据来源（引用方差较低），但通过信息压缩和推理策略将证据内化的过程引入了大量随机性。

#### Finding 6：推理模块对最终随机性影响最大

添加随机性到 $\pi_{\text{update}}$ 在所有三个指标上产生最高的最终输出随机性。这表明缓解推理阶段的随机性对实现整体系统稳定性比控制信息获取和压缩阶段的方差更有效。

### 缓解实验结果

| 方法 | 准确率 | 平均TV |
|------|--------|--------|
| 基线 | 0.24 | 0.69 |
| 结构化压缩 | 0.28 | 0.67 |
| 结构化推理 | 0.32 | 0.62 |
| 结构化组合 | 0.36 | 0.56 |
| 查询交集 | 0.32 | 0.62 |
| **组合方法** | **0.36** | **0.47** |

组合方法实现了最低随机性（0.47），同时准确率提高12%（相对提升50%），平均随机性降低22%。

---

## 6. 优势分析

1. **理论框架的创新性**：首次将信息获取MDP形式化应用于DRA随机性分析，提供了坚实的数学基础
2. **随机性分解的完整性**：不仅识别随机性存在，还将其分解为可操作的两个层次（传播/内在）和三个模块（查询/压缩/推理）
3. **实验设计的严谨性**：使用温度消融进行受控实验，清晰分离不同模块和时间步骤的贡献
4. **缓解策略的有效性**：结构化输出+查询集成的组合方法展示了随机性可被显著降低而不损害质量
5. **发现的关键洞察**：Finding 4和Finding 6对实际系统设计有重要指导意义

---

## 7. 局限性与问题

### 理论限制

1. **分解的近似性**：论文承认精确数学分解传播随机性和内在随机性在计算上不可行，当前分析依赖近似方法
2. **环境假设**：假设 $\beta_{\text{env}}$ 固定（即通过缓存或可重现搜索），但现实世界搜索API可能有更多随机性

### 可扩展性问题

1. **计算成本**：运行10次独立实验以估计随机性的方法在大规模应用时可能成本高昂
2. **任务泛化**：实验仅在QA类型数据集（WebWalkerQA、DeepSearchQA）上验证，未探索开放域研究任务

### 数据依赖

1. **搜索API依赖**：使用You.com API，结果可能随搜索引擎算法更新而变化
2. **LLM版本依赖**：使用特定版本的Qwen3，结果可能随模型更新而变化

### 可复现性问题

1. **API非确定性**：论文提到即使设置temperature=0，API推理仍可能非确定性（"API inference is non-batch invariant"）
2. **时间窗口限制**：实验在50小时窗口内进行以最小化搜索索引更新影响

### 潜在偏见

1. **数据集偏见**：仅在两个数据集上验证，结论泛化性待定
2. **搜索API偏见**：依赖特定搜索引擎可能引入系统级偏见

---

## 8. 与现有LLM研究的联系

### 与RAG研究的关系

本文继承自RAG（检索增强生成）的知识密集型问答传统，但扩展到需要迭代工具使用和长文本生成的研究任务。关键区别在于：RAG主要关注单次检索-生成，而DRA需要多轮迭代的检索-压缩-推理循环。

### 与Agent研究的联系

与当前主流Agent研究（如ReAct、Toolformer、AgentLM）关注工具使用和推理能力不同，本文首次系统性地关注Agent系统部署的可靠性问题——随机性。这是Agent从实验室走向真实应用的关键桥梁。

### 与评估研究的联系

与传统的准确率/质量评估不同，本文提出随机性作为独立维度进行评估。这为Agent系统的全面评估提供了新视角——一个高质量但高随机性的系统可能不如中等质量但低随机性的系统有用。

---

## 9. 深度批判性思考

### 论文的"真正创新"是否成立？

**是的，但有新意。** 随机性问题在LLM研究中已被关注（如"Defeating nondeterminism in LLM inference"），但将其系统性地形式化并分解到Agent架构的模块级别是首次。更重要的是，论文不仅分析问题，还提供了可操作的缓解策略，并验证了其有效性。

### 是否只是engineering stacking？

**不完全是。** 虽然缓解方法（结构化输出、查询集成）是工程技巧，但背后的理论框架（信息获取MDP、随机性分解）提供了原则性分析基础。这种"理论指导工程"的路径比单纯堆叠工程技巧更有说服力。

### 有哪些关键实验缺失？

1. **更大规模验证**：仅在20个实例上验证，统计意义有限
2. **更多基线模型**：仅使用Qwen3系列，未对比GPT-4、Claude等闭源模型
3. **真实用户研究**：缺乏真实用户对随机性感知的主观评估
4. **长尾任务**：仅在QA类型任务上验证，未探索开放域研究

### 隐含假设

1. **搜索一致性假设**：假设搜索引擎对相同查询返回一致结果，但现实中搜索结果可能随时间、地理位置、用户画像等因素变化
2. **可重复性假设**：假设可以通过多次运行来估计随机性，但某些应用场景可能无法容忍重复执行

### 未来改进方向

1. **更细粒度的随机性控制**：不仅控制温度，还可以控制采样策略（top-k、top-p）
2. **自适应缓解**：根据任务复杂度动态调整缓解策略强度
3. **理论保证**：探索是否能提供随机性减少的理论上界
4. **多模态扩展**：当前仅关注文本搜索，未来可扩展到图像、视频等多模态信息获取

### 对实践的启示

这篇论文对DRA系统设计者提供了重要启示：

1. **优先控制早期随机性**：由于早期随机性传播最强，应优先对初始查询生成和早期推理进行约束
2. **推理模块是关键**：推理策略对最终随机性贡献最大，应投入最多精力优化
3. **随机性 ≠ 质量**：不要假设增加随机性（如更高温度）会带来更好的结果，实验表明恰恰相反
4. **结构化输出的重要性**：简单的结构化约束可以显著降低随机性，值得广泛采用

---

## 总结

这篇论文成功地将一个常被忽视但至关重要的实际问题——深度研究Agent的随机性——推到了研究前沿。通过信息获取MDP的优雅形式化、系统的随机性分解框架、以及有效的缓解策略，论文为构建更可靠、更可复现的DRA系统奠定了基础。最关键的发现（高随机性不导致高准确性、推理模块贡献最大）为未来Agent系统设计提供了明确指导。随着DRA在实际应用中的普及，这项研究的价值将愈发凸显。

---

*本文基于arXiv:2602.23271论文内容撰写，分析仅代表个人观点，仅供参考。*
